{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained BERT model for phrase/sentence similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list of \"I tested positive\" phrases\n",
    "covid_synonyms = [\"covid-19\",\"covid19\",\"covid\",\"coronavirus\",\"corona\",\"rona\"]\n",
    "positive_phrases = [\n",
    "    \"I tested positive\",\n",
    "    \"since my <covid> diagnosis\",\n",
    "    \"since my positive diagnosis\",\n",
    "    \"after my positive diagnosis\",\n",
    "    \"ater testing positive\",\n",
    "    \"I had <covid>\",\n",
    "    \"I got <covid>\",\n",
    "    \"diagnosed with <covid>\",\n",
    "    \"it has been since I had <covid>\",\n",
    "]\n",
    "# create list of covid positive phrases using list of commonly used synonyms\n",
    "all_phrases = []\n",
    "for phrase in positive_phrases:\n",
    "    for syn in covid_synonyms:\n",
    "        all_phrases.append(phrase.replace(\"<covid>\",syn))\n",
    "\n",
    "# create text/vector embeddings for each phrase\n",
    "positive_embedding_map = {}\n",
    "for phrase in all_phrases:\n",
    "    embedding = model.encode(phrase, convert_to_tensor=True)\n",
    "    positive_embedding_map[phrase] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from sqlite DB\n",
    "datadir = r\"C:\\Users\\keatu\\Regis_archive\\practicum_data\"\n",
    "dbfile = os.path.join(datadir,\"Facebook_self_report.db\")\n",
    "con = sqlite3.connect(dbfile)\n",
    "posts = pd.read_sql(\"select * from posts\",con)\n",
    "comments = pd.read_sql(\"select * from comments\", con)\n",
    "replies = pd.read_sql(\"Select * from replies\",con)\n",
    "con.close()\n",
    "\n",
    "# grab text/id fields from each data type--treating them all like unique posts\n",
    "all_text = pd.concat([\n",
    "                    posts[[\"user_id\",\"post_id\",\"text\"]],\n",
    "                    comments[[\"commenter_id\",\"comment_id\",\"comment_text\"]].rename(columns={\"commenter_id\":\"user_id\",\"comment_id\":\"post_id\",\"comment_text\":\"text\"}),\n",
    "                    replies[[\"commenter_id\",\"comment_id\",\"comment_text\"]].rename(columns={\"commenter_id\":\"user_id\",\"comment_id\":\"post_id\",\"comment_text\":\"text\"})\n",
    "                    ], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare input sentence embedding to all matching sentence combinations and use threshold cosine similarity score\n",
    "positive_report_df = pd.DataFrame()\n",
    "threshold = 0.75 # cosine similarity threshold\n",
    "i=0\n",
    "for idx, row in all_text.iterrows():\n",
    "    i=+1\n",
    "    if (i%1000)==0:\n",
    "        print(\"{} completed of {}\".format(i,len(all_text)))\n",
    "    for sent in sent_tokenize(row['text']):\n",
    "        sent_embed = model.encode(sent, convert_to_tensor=True)\n",
    "        top_score = 0\n",
    "        top_match = \"\"\n",
    "        for phrase in positive_embedding_map:\n",
    "            cos_score = util.cos_sim(sent_embed, positive_embedding_map[phrase]).item()\n",
    "            if cos_score > top_score:\n",
    "                top_score = cos_score\n",
    "                top_match = phrase\n",
    "        if top_score > threshold:\n",
    "            #print(\"sentence: {}, phrase: {}, score: {}\".format(sent, top_match, top_score))\n",
    "            positive_report_df = positive_report_df.append({'user_id':row['user_id'],\"post_id\":row['post_id'],'sentence':sent,\"match_sentence\":top_match,\"cos_similarity\":top_score}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcon = sqlite3.connect(r\"C:\\Users\\keatu\\Regis_archive\\practicum_data\\Facebook_Self_Report.db\")\n",
    "positive_report_df.astype(str).to_sql(\"positive_reporting\",con=outcon)\n",
    "outcon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_time = pd.concat([\n",
    "                    posts[[\"user_id\",\"post_id\",\"text\",\"time\"]],\n",
    "                    comments[[\"commenter_id\",\"comment_id\",\"comment_text\",\"comment_time\"]].rename(columns={\"commenter_id\":\"user_id\",\"comment_id\":\"post_id\",\"comment_text\":\"text\",\"comment_time\":\"time\"}),\n",
    "                    replies[[\"commenter_id\",\"comment_id\",\"comment_text\",\"comment_time\"]].rename(columns={\"commenter_id\":\"user_id\",\"comment_id\":\"post_id\",\"comment_text\":\"text\",\"comment_time\":\"time\"})\n",
    "                    ], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_report_with_time = pd.merge(positive_report_df,text_with_time[[\"post_id\",\"time\"]], on=\"post_id\", how=\"left\").sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_report_with_time.to_csv(os.path.join(datadir,\"positive_reporting.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reporting = pd.read_csv(os.path.join(datadir,\"positive_reporting.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcon = sqlite3.connect(r\"C:\\Users\\keatu\\Regis_archive\\practicum_data\\Facebook_Self_Report.db\")\n",
    "positive_reporting[~positive_reporting[\"date_reported\"].isna()].astype(str).to_sql(\"positive_reporting\",con=outcon)\n",
    "outcon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_report_with_time = pd.merge(positive_report_df,text_with_time[[\"post_id\",\"time\"]], on=\"post_id\", how=\"left\").sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = r\"C:\\Users\\keatu\\Regis_archive\\practicum_data\"\n",
    "dbfile = os.path.join(datadir,\"Facebook_self_report.db\")\n",
    "con = sqlite3.connect(dbfile)\n",
    "self_report = pd.read_sql(\"select * from self_reporting\",con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_report_w_time = pd.merge(self_report,text_with_time[[\"post_id\",\"time\",\"text\"]], on=\"post_id\", how=\"left\").sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reporting_trim = positive_reporting[~positive_reporting[\"date_reported\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ids = [str(i) for i in positive_reporting_trim.user_id.unique().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_report_w_time[self_report_w_time['user_id'].isin(pos_ids)].to_csv(os.path.join(datadir,\"self_reporting_of_interest.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce4da9915f0d678e12335d58837d25529fa567b369eed2b2f7083145c2fca737"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
